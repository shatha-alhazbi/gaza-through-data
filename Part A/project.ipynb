{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44b40586",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "# You might need to **install otter** package. Use `pip install otter-grader` for that.\n",
    "import otter\n",
    "grader = otter.Notebook(\"project.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b67b7db",
   "metadata": {},
   "source": [
    "# Project Part A: Climate Changeâ€”Temperatures and Precipitation\n",
    "\n",
    "In this part of the project, you will investigate data on climate change, or the long-term shifts in temperatures and weather patterns!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60b8b76",
   "metadata": {},
   "source": [
    "### Logistics\n",
    "\n",
    "**Start Early!** **Do NOT** wait until the last few days!\n",
    "\n",
    "**Rules.** **DO NOT** share your code with anybody but your team mates. The experience of solving the problems in this project will prepare you for exams (and life). \n",
    "\n",
    "**Discussion.** There might be a discussion with your team to discuss your solution after submission.\n",
    "\n",
    "**Support.** You are not alone! Come to office hours and talk to your team mates. If you're ever feeling overwhelmed or don't know how to make progress, email for help.\n",
    "\n",
    "**Tests.** The tests that are given are **not comprehensive** and passing the tests for a question **does not** mean that you answered the question correctly. Tests usually only check that your table has the correct column labels. However, more tests will be applied to verify the correctness of your submission in order to assign your final score, so be careful and check your work! You might want to create your own checks along the way to see if your answers make sense. Additionally, before you submit, make sure that none of your cells take a very long time to run (several minutes).\n",
    "\n",
    "**Otter.** You might need to **install otter** package. Use `pip install otter-grader` for that.\n",
    "\n",
    "**Free Response Questions:** Make sure that you put the answers to the written questions in the indicated cell we provide. **Every free response question should include an explanation** that adequately answers the question. \n",
    "\n",
    "**Advice.** Develop your answers incrementally. To perform a complicated task, break it up into steps, perform each step on a different line, give a new name to each result, and check that each intermediate result is what you expect. You can add any additional names or functions you want to the provided cells. Make sure that you are using distinct and meaningful variable names throughout the notebook. Along that line, **DO NOT** reuse the variable names that we use when we grade your answers. \n",
    "\n",
    "You **never** have to use just one line in this project. Use intermediate variables and multiple lines as much as you would like!\n",
    "\n",
    "All of the concepts necessary for this project are found in the textbook. If you are stuck on a particular problem, reading through the relevant textbook section often will help clarify the concept.\n",
    "\n",
    "---\n",
    "\n",
    "To get started, load `datascience`, `numpy`, `matplotlib`, and `d8error`. Make sure to also run the first cell of this notebook to load `otter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed3e0b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:15.381590Z",
     "iopub.status.busy": "2022-04-01T19:48:15.381212Z",
     "iopub.status.idle": "2022-04-01T19:48:16.995289Z",
     "shell.execute_reply": "2022-04-01T19:48:16.994134Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to set up the notebook, but please don't change it.\n",
    "from datascience import *\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "np.set_printoptions(legacy='1.13')\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import d8error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419c3e66",
   "metadata": {},
   "source": [
    "## Part A.1: Temperatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12648c5d",
   "metadata": {},
   "source": [
    "In the following analysis, we will investigate one of the 21st century's most prominent issues: climate change. While the details of climate science are beyond the scope of this course, we can start to learn about climate change just by analyzing public records of different cities' temperature and precipitation over time.\n",
    "\n",
    "We will analyze a collection of historical daily temperature and precipitation measurements from weather stations in 210 U.S. cities. The dataset was compiled by Yuchuan Lai and David Dzombak [1]; a description of the data from the original authors and the data itself is available [here](https://kilthub.cmu.edu/articles/dataset/Compiled_daily_temperature_and_precipitation_data_for_the_U_S_cities/7890488). \n",
    "\n",
    "[1] Lai, Yuchuan; Dzombak, David (2019): Compiled historical daily temperature and precipitation data for selected 210 U.S. cities. Carnegie Mellon University. Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dc3ca2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Part A.1, Section 1: Cities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cac3393",
   "metadata": {},
   "source": [
    "Run the following cell to load information about the `cities` and preview the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13b281c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:17.000245Z",
     "iopub.status.busy": "2022-04-01T19:48:16.999397Z",
     "iopub.status.idle": "2022-04-01T19:48:17.018421Z",
     "shell.execute_reply": "2022-04-01T19:48:17.016873Z"
    }
   },
   "outputs": [],
   "source": [
    "cities = Table.read_table('city_info.csv', index_col=0)\n",
    "cities.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681a3b8b",
   "metadata": {},
   "source": [
    "The `cities` table has one row per weather station and the following columns:\n",
    "\n",
    "1. `\"Name\"`: The name of the US city\n",
    "2. `\"ID\"`: The unique identifier for the US city\n",
    "3. `\"Lat\"`: The latitude of the US city (measured in degrees of latitude)\n",
    "4. `\"Lon\"`: The longitude of the US city (measured in degrees of longitude)\n",
    "4. `\"Stn.Name\"`: The name of the weather station in which the data was collected\n",
    "5. `\"Stn.stDate\"`: A string representing the date of the first recording at that particular station\n",
    "6. `\"Stn.edDate\"`: A string representing the date of the last recording at that particular station\n",
    "\n",
    "The data lists the weather stations at which temperature and precipitation data were collected. Note that although some cities have multiple weather stations, only one is collecting data for that city at any given point in time. Thus, we are able to just focus on the cities themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a003db",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.1.1:** In the cell below, produce a scatter plot that plots the latitude and longitude of every city in the `cities` table so that the result places northern cities at the top and western cities at the left.\n",
    "\n",
    "*Note*: It's okay to plot the same point multiple times!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacafb00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:17.023055Z",
     "iopub.status.busy": "2022-04-01T19:48:17.022765Z",
     "iopub.status.idle": "2022-04-01T19:48:17.350971Z",
     "shell.execute_reply": "2022-04-01T19:48:17.349623Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dc64e8",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "These cities are all within the continental U.S., and so the general shape of the U.S. should be visible in your plot. The shape will appear distorted compared to most maps for two reasons: the scatter plot is square even though the U.S. is wider than it is tall, and this scatter plot is an [equirectangular projection](https://en.wikipedia.org/wiki/Equirectangular_projection) of the spherical Earth. A geographical map of the same data uses the common [Pseudo-Mercator projection](https://en.wikipedia.org/wiki/Web_Mercator_projection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b825c490",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:17.356104Z",
     "iopub.status.busy": "2022-04-01T19:48:17.355254Z",
     "iopub.status.idle": "2022-04-01T19:48:18.357388Z",
     "shell.execute_reply": "2022-04-01T19:48:18.356174Z"
    }
   },
   "outputs": [],
   "source": [
    "# Just run this cell\n",
    "Marker.map_table(cities.select('Lat', 'Lon', 'Name').relabeled('Name', 'labels'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d368b6",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.1.2** Does it appear that these city locations are sampled uniformly at random from all the locations in the U.S.? Why or why not?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393bb8fe",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7578589",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 1.1.3:** Assign `num_unique_cities` to the number of unique cities that appear in the `cities` table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b110d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:18.368079Z",
     "iopub.status.busy": "2022-04-01T19:48:18.367301Z",
     "iopub.status.idle": "2022-04-01T19:48:18.391902Z",
     "shell.execute_reply": "2022-04-01T19:48:18.390553Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_unique_cites = ...\n",
    "\n",
    "# Do not change this line\n",
    "print(f\"There are {num_unique_cites} unique cities that appear within our dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967a5991",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cef018",
   "metadata": {},
   "source": [
    "In order to investigate further, it will be helpful to determine what region of the United States each city was located in: Northeast, Northwest, Southeast, or Southwest. For our purposes, we will be using the following geographical boundaries:\n",
    "\n",
    "<img src= \"usa_coordinates.png\" alt=\"USA Coordinate Map\" width=\"600\"/>\n",
    "\n",
    "1. A station is located in the `\"Northeast\"` region if its latitude is above or equal to 40 degrees and its longtitude is greater than or equal to -100 degrees.\n",
    "2. A station is located in the `\"Northwest\"` region if its latitude is above or equal to 40 degrees and its longtitude is less than -100 degrees.\n",
    "3. A station is located in the `\"Southeast\"` region if its latitude is below 40 degrees and its longtitude is greater than or equal to -100 degrees.\n",
    "4. A station is located in the `\"Southwest\"` region if its latitude is below 40 degrees and its longtitude is less than -100 degrees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fdf4ad",
   "metadata": {},
   "source": [
    "**Question 1.1.4**: Define the `coordinates_to_region` function below. It should take in two arguments, a city's latitude (`lat`) and longitude (`lon`) coordinates, and output a string representing the region it is located in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb22d1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:18.451859Z",
     "iopub.status.busy": "2022-04-01T19:48:18.451565Z",
     "iopub.status.idle": "2022-04-01T19:48:18.457133Z",
     "shell.execute_reply": "2022-04-01T19:48:18.456189Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def coordinates_to_region(...):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93c0d65",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_1_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd63dbb7",
   "metadata": {},
   "source": [
    "**Question 1.1.5**: Add a new column in `cities` labeled `Region` that contains the region in which the city is located. For full credit, you must use the `coordinates_to_region` function you defined rather than reimplementing its logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e592720",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:18.556390Z",
     "iopub.status.busy": "2022-04-01T19:48:18.555478Z",
     "iopub.status.idle": "2022-04-01T19:48:18.563153Z",
     "shell.execute_reply": "2022-04-01T19:48:18.562375Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "regions_array = ...\n",
    "cities = ...\n",
    "cities.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eed3340",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_1_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ba6d6a",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.1.6**: To confirm that you've defined your `coordinates_to_region` function correctly and successfully added the `Region` column to the `cities` table, produce a scatter plot similar to the one in Question 1.1.1, but here each region should have a different color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06559a4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:18.679008Z",
     "iopub.status.busy": "2022-04-01T19:48:18.678343Z",
     "iopub.status.idle": "2022-04-01T19:48:18.982745Z",
     "shell.execute_reply": "2022-04-01T19:48:18.981716Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0712408a",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 1.1.7**: Create a new table called `cities_nearest`. It should contain the same columns as the `cities` table and an additional column called `\"Nearest\"` that contains the **name of the nearest city** that is in a different region from the city described by the row.\n",
    "\n",
    "To approximate the distance between two cities, take the square root of the sum of the squared difference between their latitudes and the square difference between their longitudes. Don't use a `for` statement; instead, use the `apply` method and array arithmetic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad4aee7",
   "metadata": {},
   "source": [
    "**Question 1.1.7**: Create a new table called `regions_focus`, which has only two columns `Region` and `City` and has one row per region, that has the name of the city with the largest number of stations within that region. You are NOT permitted to use any loop statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f90eb9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "regions_focus = ...\n",
    "regions_focus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8daa022",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_1_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9e7603",
   "metadata": {},
   "source": [
    "### Part A.1, Section 2: Welcome to Phoenix, Arizona"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c96713a",
   "metadata": {},
   "source": [
    "Each city has a different CSV file full of daily temperature and precipitation measurements. The file for Phoenix, Arizona is included with this project as `phoenix.csv`. The files for other cities can be downloaded [here](https://kilthub.cmu.edu/articles/dataset/Compiled_daily_temperature_and_precipitation_data_for_the_U_S_cities/7890488) by matching them to the ID of the city in the `cities` table.\n",
    "\n",
    "Since Phoenix is located on the upper edge of the Sonoran Desert, it has some impressive temperatures.\n",
    "\n",
    "Run the following cell to load in the `phoenix` table. It has one row per day and the following columns:\n",
    "\n",
    "1. `\"Date\"`: The date (a string) representing the date of the recording in **YYYY-MM-DD** format\n",
    "2. `\"tmax\"`: The maximum temperature for the  day (Â°F)\n",
    "3. `\"tmin\"`: The minimum temperature for the day (Â°F)\n",
    "4. `\"prcp\"`: The recorded precipitation for the day (inches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08932ae0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:19.809733Z",
     "iopub.status.busy": "2022-04-01T19:48:19.809458Z",
     "iopub.status.idle": "2022-04-01T19:48:19.919734Z",
     "shell.execute_reply": "2022-04-01T19:48:19.918491Z"
    }
   },
   "outputs": [],
   "source": [
    "phoenix = Table.read_table(\"phoenix.csv\", index_col=0)\n",
    "phoenix.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec79085",
   "metadata": {},
   "source": [
    "**Question 1.2.1:** Assign the variable `largest_2010_range_date` to the date of the **largest temperature range** in Phoenix, Arizona for any day between January 1st, 2010 and December 31st, 2010. Your answer should be a string in the \"YYYY-MM-DD\" format. Feel free to use as many lines as you need. A temperature range is calculated as the difference between the max and min temperatures for the day.\n",
    "\n",
    "*Hint*: To limit the values in a column to only those that *contain* a certain string, pick the right `are.` predicate from the [Python Reference Sheet](http://data8.org/sp22/python-reference.html).\n",
    "\n",
    "*Note:* Do **not** re-assign the `phoenix` variable; please use the `phoenix_with_ranges_2010` variable instead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341858ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:19.923597Z",
     "iopub.status.busy": "2022-04-01T19:48:19.923362Z",
     "iopub.status.idle": "2022-04-01T19:48:19.966729Z",
     "shell.execute_reply": "2022-04-01T19:48:19.965765Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "phoenix_with_ranges_2010 = ...\n",
    "largest_2010_range_date = ...\n",
    "largest_2010_range_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeae9fc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5120822",
   "metadata": {},
   "source": [
    "We can look back to our `phoenix` table to check the temperature readings for our `largest_2010_range_date` to see if anything special is going on. Run the cell below to find the row of the `phoenix` table that corresponds to the date we found above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2324a71c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:19.988378Z",
     "iopub.status.busy": "2022-04-01T19:48:19.988158Z",
     "iopub.status.idle": "2022-04-01T19:48:20.065916Z",
     "shell.execute_reply": "2022-04-01T19:48:20.065120Z"
    }
   },
   "outputs": [],
   "source": [
    "# Just run this cell\n",
    "phoenix.where(\"Date\", largest_2010_range_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cfdb12",
   "metadata": {},
   "source": [
    "OOH! Look at the maximum temperature for that day. That's hot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7150fdaf",
   "metadata": {},
   "source": [
    "The function `extract_year_from_date` takes a date string in the **YYYY-MM-DD** format and returns an integer representing the **year**. The function `extract_month_from_date` takes a date string and returns a string describing the month. Run this cell, and you do not need to edit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188a4542",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:20.069363Z",
     "iopub.status.busy": "2022-04-01T19:48:20.069132Z",
     "iopub.status.idle": "2022-04-01T19:48:20.076243Z",
     "shell.execute_reply": "2022-04-01T19:48:20.075163Z"
    }
   },
   "outputs": [],
   "source": [
    "# Just run this cell\n",
    "import calendar\n",
    "\n",
    "def extract_year_from_date(date):\n",
    "    \"\"\"Returns an integer corresponding to the year of the input string's date.\"\"\"\n",
    "    return int(date[:4])\n",
    "\n",
    "def extract_month_from_date(date):\n",
    "    \"Return an abbreviation of the name of the month for a string's date.\"\n",
    "    month = date[5:7]\n",
    "    return f'{month} ({calendar.month_abbr[int(date[5:7])]})'\n",
    "\n",
    "\n",
    "# Example\n",
    "print('2022-04-01 has year', extract_year_from_date('2022-04-01'),\n",
    "      'and month', extract_month_from_date('2022-04-01'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25adea36",
   "metadata": {},
   "source": [
    "**Question 1.2.2:** Add two new columns called `Year` and `Month` to the `phoenix` table that contain the year as an **integer** and the month as a **string** (such as `\"04 (Apr)\"`) for each day, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28480b9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:20.080472Z",
     "iopub.status.busy": "2022-04-01T19:48:20.080241Z",
     "iopub.status.idle": "2022-04-01T19:48:20.313030Z",
     "shell.execute_reply": "2022-04-01T19:48:20.311830Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "years_array = ...\n",
    "months_array = ...\n",
    "...\n",
    "phoenix.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c1fd19",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_2_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56dbe35",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.2.3:** Using the `phoenix` table, create an overlaid line plot of the **average maximum temperature** and **average minimum temperature** for each year between 1900 and 2020 (inclusive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4219418",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:24.101776Z",
     "iopub.status.busy": "2022-04-01T19:48:24.100683Z",
     "iopub.status.idle": "2022-04-01T19:48:25.549633Z",
     "shell.execute_reply": "2022-04-01T19:48:25.548857Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ebd2e",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.2.4:** Although still hotly debated, many climate scientists agree that the effects of climate change began to surface in the early 1960s as a result of elevated levels of greenhouse gas emissions. How does the graph you produced in Question 1.2.3 support the claim that modern-day global warming began in the early 1960s? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c5ec45",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58e7578",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "Averaging temperatures across an entire year can obscure some effects of climate change. For example, if summers get hotter but winters get colder, the annual average may not change much. Let's investigate how average **monthly** maximum temperatures have changed over time in Phoenix. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e64e7d7",
   "metadata": {},
   "source": [
    "**Question 1.2.5:** Create a `monthly_increases` table with one row per month and the following four columns in order: \n",
    "1. `\"Month\"`: The month (such as `\"02 (Feb)\"`)\n",
    "2. `\"Past\"`: The average max temperature in that month from 1900-1960 (inclusive)\n",
    "3. `\"Present\"`: The average max temperature in that month from 2019-2021 (inclusive)\n",
    "4. `\"Increase\"`: The difference between the present and past average max temperatures in that month\n",
    "\n",
    "First, you need to define the `period` function as stated above. Next make a copy of the `phoenix` table and add a new column containing the corresponding **period** for each row. Then, use this new table to construct `monthly_increases`. Feel free to use as many lines as you need.\n",
    "\n",
    "*Note*: Please do **not** re-assign the `phoenix` variable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c938a824",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:25.553330Z",
     "iopub.status.busy": "2022-04-01T19:48:25.552792Z",
     "iopub.status.idle": "2022-04-01T19:48:26.960463Z",
     "shell.execute_reply": "2022-04-01T19:48:26.959613Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "def period(year):\n",
    "    ...\n",
    "monthly_increases = ...\n",
    "monthly_increases.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54793c94",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_2_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaa505a",
   "metadata": {},
   "source": [
    "### February in Phoenix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa762c20",
   "metadata": {},
   "source": [
    "The `\"Past\"` column values are averaged over many decades, and so they are reliable estimates of the average high temperatures in those months before the effects of modern climate change. However, the `\"Present\"` column is based on only three years of observations. February, the shortest month, has the fewest total observations: only 85 days. Run the following cell to see this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbaa448",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:27.008855Z",
     "iopub.status.busy": "2022-04-01T19:48:27.008626Z",
     "iopub.status.idle": "2022-04-01T19:48:27.613516Z",
     "shell.execute_reply": "2022-04-01T19:48:27.612533Z"
    }
   },
   "outputs": [],
   "source": [
    "# Just run this cell\n",
    "feb_present = phoenix.where('Year', are.between_or_equal_to(2019, 2021)).where('Month', '02 (Feb)')\n",
    "feb_present.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eaaedd",
   "metadata": {},
   "source": [
    "Look back to your `monthly_increases` table. Compared to the other months, the increase for the month of February is quite small; the February difference is very close to zero. Run the following cell to print out our observed difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25e4179",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:27.618250Z",
     "iopub.status.busy": "2022-04-01T19:48:27.617339Z",
     "iopub.status.idle": "2022-04-01T19:48:27.622910Z",
     "shell.execute_reply": "2022-04-01T19:48:27.622002Z"
    }
   },
   "outputs": [],
   "source": [
    "# Just run this cell\n",
    "print(f\"February Difference: {monthly_increases.row(1).item('Increase')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4462804",
   "metadata": {},
   "source": [
    "Perhaps that small difference is somehow due to chance! To investigate this idea requires a thought experiment.\n",
    "\n",
    "We can observe all of the February maximum temperatures from 2019 to 2021 (the present period), so we have access to the census; there's no random sampling involved. But, we can imagine that if more years pass with the same present-day climate, there would be different but similar maximum temperatures in future February days. From the data we observe, we can try to estimate the **average maximum February temperature** in this imaginary collection of all future February days that would occur in our modern climate, assuming the climate doesn't change any further and many years pass.\n",
    "\n",
    "We can also imagine that the maximum temperature each day is like a **random draw from a distribution of temperatures for that month**. Treating actual observations of natural events as if they were each *randomly* sampled from some unknown distribution is a simplifying assumption. These temperatures were not actually sampled at randomâ€”instead they occurred due to the complex interactions of the Earth's climateâ€”but treating them as if they were random abstracts away the details of this naturally occuring process and allows us to carry out statistical inference.  Conclusions are only as valid as the assumptions upon which they rest, but in this case thinking of daily temperatures as random samples from some unknown climate distribution seems at least plausible.\n",
    "\n",
    "If we assume that the **actual temperatures were drawn at random from some large population of possible February days** in our modern climate, then we can not only estimate the population average of this distribution, but also quantify our uncertainty about that estimate using a confidence interval.\n",
    "\n",
    "**We will just compute the lower bound of this confidence interval.** The upper bound of a confidence interval for a population average based on a sample is always larger than the sample average. We intend to compare our confidence interval to the historical average (ie. the `Past` value in our `monthly_increases` table). In all months, the sample average we will consider (i.e. the `Present` value in our `monthly_increases` table) is larger than the historical average. As a result, we know in advance that the upper bound of the confidence interval will be larger as well, and there is no need to compute the upper bound explicitly. (But you can if you wish!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ded04f4",
   "metadata": {},
   "source": [
    "**Question 1.2.6.** Complete the implementation of the function `ci_lower`, which takes a one-column table `t` containing sample observations and a confidence `level` percentage such as 95 or 99. It returns the lower bound of a confidence interval for the population mean constructed using 5,000 bootstrap resamples.\n",
    "\n",
    "After defining `ci_lower`, we have provided a line of code that calls `ci_lower` on the present-day February max temperatures to output the lower bound of a 99% confidence interval for the February average max temperature. The result should be around 67 degrees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfe2a1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:27.626753Z",
     "iopub.status.busy": "2022-04-01T19:48:27.626488Z",
     "iopub.status.idle": "2022-04-01T19:48:28.204870Z",
     "shell.execute_reply": "2022-04-01T19:48:28.204070Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ci_lower(t, level):\n",
    "    \"\"\"Compute a lower bound of a level% confidence interval of the \n",
    "    average of the population for which column 0 of Table t contains a sample.\n",
    "    \"\"\"\n",
    "\n",
    "# Call ci_lower on the max temperatures in present-day February to find the lower bound of a 99% confidence interval.\n",
    "feb_present_ci = ci_lower(feb_present.select('tmax'), 99)\n",
    "feb_present_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dac9b9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_2_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab01313f",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.2.7** The lower bound of the `feb_present_ci` 99% confidence interval is below the observed past February average maximum temperature of 68.8485 (from the `monthly_increases` table). What conclusion can you draw about the effect of climate change on February maximum temperatures in Phoenix from this information? Use a 1% p-value cutoff?\n",
    "\n",
    "*Note*: If you're stuck on this question, re-reading the paragraphs under the *February* heading (particularly the first few) may be helpful.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf2f11f",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2669d8ab",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### All Months"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8572c2",
   "metadata": {},
   "source": [
    "**Question 1.2.8.** Repeat the process of comparing the **lower bound of a 99% confidence interval** to the **past average** for each month. For each month, print out the name of the month (e.g., `02 (Feb)`), the observed past average, and the lower bound of a confidence interval for the present average.\n",
    "\n",
    "Use the provided call to `print` in order to format the result as one line per month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b35b17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:28.218743Z",
     "iopub.status.busy": "2022-04-01T19:48:28.217687Z",
     "iopub.status.idle": "2022-04-01T19:48:41.740943Z",
     "shell.execute_reply": "2022-04-01T19:48:41.740229Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "comparisons = ...\n",
    "months = ...\n",
    "for month in months:\n",
    "    past_average = ...\n",
    "    present_observations = ...\n",
    "    present_lower_bound = ...\n",
    "    \n",
    "    # Do not change the code below this line\n",
    "    below = past_average < present_lower_bound\n",
    "    if below:\n",
    "        comparison = '**below**'\n",
    "    else:\n",
    "        comparison = '*above*'\n",
    "    comparisons = np.append(comparisons, comparison)\n",
    "    \n",
    "    print('For', month, 'the past avg', round(past_average, 1), \n",
    "          'is', comparison, \n",
    "          'the lower bound', round(present_lower_bound, 1),\n",
    "          'of the 99% CI of the present avg. \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a7bcda",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_2_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cbf029",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.2.9.** Summarize your findings. After comparing the past average to the 99% confidence interval's lower bound for each month, what conclusions can we make about the monthly average maximum temperature in historical (1900-1960) vs. modern (2019-2021) times in the twelve months? In other words, what null hypothesis should you consider, and for which months would you reject or fail to reject the null hypothesis? Use a 1% p-value cutoff.\n",
    "\n",
    "*Hint*: Do you notice any seasonal patterns?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfc724a",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2152dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Congratulations\n",
    "\n",
    "Congratulations, you made it this far! You are done with Part A.1!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a670894",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part A.2: Drought"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b6394e",
   "metadata": {},
   "source": [
    "According to the [United States Environmental Protection Agency](https://www.epa.gov/climate-indicators/southwest), \"Large portions of the Southwest have experienced drought conditions since weekly Drought Monitor records began in 2000. For extended periods from 2002 to 2005 and from 2012 to 2020, nearly the entire region was abnormally dry or even drier.\" \n",
    "\n",
    "Assessing the impact of drought is challenging with just city-level data because so much of the water that people use is transported from elsewhere, but we'll explore the data we have and see what we can learn.\n",
    "\n",
    "Let's first take a look at the precipitation data in the Southwest region. The `southwest.csv` file contains total annual precipitation for 13 cities in the southwestern United States for each year from 1960 to 2021. This dataset is aggregated from the daily data and includes only the Southwest cities from the original dataset that have consistent precipitation records back to 1960."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13197165",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:42.449134Z",
     "iopub.status.busy": "2022-04-01T19:48:42.448288Z",
     "iopub.status.idle": "2022-04-01T19:48:42.460904Z",
     "shell.execute_reply": "2022-04-01T19:48:42.459792Z"
    }
   },
   "outputs": [],
   "source": [
    "southwest = Table.read_table('southwest.csv')\n",
    "southwest.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17234215",
   "metadata": {},
   "source": [
    "**Question 2.1.** Create a table `totals` that has one row for each year in chronological order. It should contain the following columns:\n",
    "1. `\"Year\"`: The year (a number)\n",
    "2. `\"Precipitation\"`: The total precipitation in all 13 southwestern cities that year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d8076f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:42.464953Z",
     "iopub.status.busy": "2022-04-01T19:48:42.464638Z",
     "iopub.status.idle": "2022-04-01T19:48:42.501131Z",
     "shell.execute_reply": "2022-04-01T19:48:42.500283Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "totals = ...\n",
    "totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0b65cf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed79b31",
   "metadata": {},
   "source": [
    "Run the cell below to plot the total precipitation in these cities over time, so that we can try to spot the drought visually. As a reminder, the drought years given by the EPA were  (2002-2005) and (2012-2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6607065",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:42.581494Z",
     "iopub.status.busy": "2022-04-01T19:48:42.581215Z",
     "iopub.status.idle": "2022-04-01T19:48:42.892093Z",
     "shell.execute_reply": "2022-04-01T19:48:42.890945Z"
    }
   },
   "outputs": [],
   "source": [
    "# Just run this cell\n",
    "totals.plot(\"Year\", \"Precipitation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d1e005",
   "metadata": {},
   "source": [
    "This plot isn't very revealing. Each year has a different amount of precipitation, and there is quite a bit of variability across years, as if each year's precipitation is a random draw from a distribution of possible outcomes. \n",
    "\n",
    "Could it be that these so-called \"drought conditions\" from 2002-2005 and 2012-2020 can be explained by chance? In other words, could it be that the annual precipitation amounts in the Southwest for these drought years are like **random draws from the same underlying distribution** as for other years? Perhaps nothing about the Earth's precipitation patterns has really changed, and the Southwest U.S. just happened to experience a few dry years close together. \n",
    "\n",
    "To assess this idea, let's conduct an A/B test in which **each year's total precipitation** is an outcome, and the condition is **whether or not the year is in the EPA's drought period**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186598e5",
   "metadata": {},
   "source": [
    "This `drought_label` function distinguishes between drought years as described in the U.S. EPA statement above (2002-2005 and 2012-2020) and other years. Note that the label \"other\" is perhaps misleading, since there were other droughts before 2000, such as the massive [1988 drought](https://en.wikipedia.org/wiki/1988%E2%80%9390_North_American_drought) that affected much of the U.S. However, if we're interested in whether these modern drought periods (2002-2005 and 2012-2020) are *normal* or *abnormal*, it makes sense to distinguish the years in this way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb029b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:42.898622Z",
     "iopub.status.busy": "2022-04-01T19:48:42.897065Z",
     "iopub.status.idle": "2022-04-01T19:48:42.904852Z",
     "shell.execute_reply": "2022-04-01T19:48:42.903832Z"
    }
   },
   "outputs": [],
   "source": [
    "def drought_label(n):\n",
    "    \"\"\"Return the label for an input year n.\"\"\"\n",
    "    if 2002 <= n <= 2005 or 2012 <= n <= 2020:\n",
    "        return 'drought'\n",
    "    else:\n",
    "        return 'other'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce25102",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 2.2.** Define null and alternative hypotheses for an A/B test that investigates whether drought years are drier (have less precipitation) than other years.\n",
    "\n",
    "*Note:* Please format your answer using the following structure.\n",
    "\n",
    "- *Null hypothesis:* ...\n",
    "- *Alternative hypothesis:* ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c913cc9",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0530ba18",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 2.3.** First, define the table `drought`. It should contain one row per year and the following two columns:\n",
    "- `\"Label\"`: Denotes if a year is part of a `\"drought\"` year or an `\"other\"` year\n",
    "- `\"Precipitation\"`: The sum of the total precipitation in 13 Southwest cities that year\n",
    "\n",
    "Then, construct an overlaid histogram of two observed distributions: the total precipitation in drought years and the total precipitation in other years. \n",
    "\n",
    "*Note*: Use the provided `bins` when creating your histogram, and do not re-assign the `southwest` table. Feel free to use as many lines as you need!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967678fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:42.909504Z",
     "iopub.status.busy": "2022-04-01T19:48:42.909147Z",
     "iopub.status.idle": "2022-04-01T19:48:43.268387Z",
     "shell.execute_reply": "2022-04-01T19:48:43.266900Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bins = np.arange(85, 215+1, 13)\n",
    "drought = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4931aa6b",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "Before you continue, inspect the histogram you just created and try to guess the conclusion of the A/B test. Building intuition about the result of hypothesis testing from visualizations is quite useful for data science applications. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8800d9c",
   "metadata": {},
   "source": [
    "**Question 2.4.** Our next step is to choose a test statistic based on our alternative hypothesis in Question 2.2. Which of the following options are valid choices for the test statistic? Assign `ab_test_stat` to an array of integers corresponding to valid choices. Assume averages and totals are taken over the total precipitation sums for each year.\n",
    "\n",
    "1. The difference between the **total** precipitation in **drought** years and the **total** precipitation in **other** years.\n",
    "2. The difference between the **total** precipitation in **others** years and the **total** precipitation in **drought** years.\n",
    "3. The **absolute** difference between the **total** precipitation in others years and the **total** precipitation in drought years.\n",
    "1. The difference between the **average** precipitation in **drought** years and the **average** precipitation in **other** years.\n",
    "2. The difference between the **average** precipitation in **others** years and the **average** precipitation in **drought** years.\n",
    "3. The **absolute** difference between the **average** precipitation in others years and the **average** precipitation in drought years.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce0f349",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:43.273156Z",
     "iopub.status.busy": "2022-04-01T19:48:43.272189Z",
     "iopub.status.idle": "2022-04-01T19:48:43.277227Z",
     "shell.execute_reply": "2022-04-01T19:48:43.276223Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ab_test_stat = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4972cc6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d264a6f5",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 2.5.** Fellow climate scientists Olivia and Will point out that there are more **other** years than **drought** years, and so measuring the difference between total precipitation will always favor the **other** years. They conclude that all of the options above involving **total** precipitation are invalid test statistic choices. Do you agree with them? Why or why not?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebf1ecb",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6de440",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "Before going on, check your `drought` table. It should have two columns `Label` and `Precipitation` with 61 rows, 13 of which are for `\"drought\"` years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e15d4b",
   "metadata": {},
   "source": [
    "**Question 2.6.** For our A/B test, we'll use the difference between the average precipitation in drought years and the average precipitation in other years as our test statistic:\n",
    "\n",
    "$$\\text{average precipitation in \"drought\" years} - \\text{average precipitation in \"other\" years}$$\n",
    "\n",
    "First, complete the function `test_statistic`. It should take in a two-column table `t` with one row per year and two columns:\n",
    "- `Label`: the label for that year (either `'drought'` or `'other'`)\n",
    "- `Precipitation`: the total precipitation in the 13 Southwest cities that year. \n",
    "\n",
    "Then, use the function you define to assign `observed_statistic` to the observed test statistic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902f7981",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:43.368043Z",
     "iopub.status.busy": "2022-04-01T19:48:43.367765Z",
     "iopub.status.idle": "2022-04-01T19:48:43.377561Z",
     "shell.execute_reply": "2022-04-01T19:48:43.376586Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_statistic(t):\n",
    "    ...\n",
    "\n",
    "observed_statistic = ...\n",
    "observed_statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff6f62a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e221a48c",
   "metadata": {},
   "source": [
    "Now that we have defined our hypotheses and test statistic, we are ready to conduct our hypothesis test. Weâ€™ll start by defining a function to simulate the test statistic under the null hypothesis, and then call that function 5,000 times to construct an empirical distribution under the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654876d0",
   "metadata": {},
   "source": [
    "**Question 2.7.** Write a function to simulate the test statistic under the null hypothesis. The `simulate_precipitation_null` function should simulate the null hypothesis once (not 5,000 times) and return the value of the test statistic for that simulated sample.\n",
    "\n",
    "*Hint*: Using `t.with_column(...)` with a column name that already exists in a table `t` will replace that column with the newly specified values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e87548",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:43.464563Z",
     "iopub.status.busy": "2022-04-01T19:48:43.464340Z",
     "iopub.status.idle": "2022-04-01T19:48:43.475250Z",
     "shell.execute_reply": "2022-04-01T19:48:43.474197Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simulate_precipitation_null():\n",
    "    ...\n",
    "\n",
    "# Run your function a couple times to make sure that it works\n",
    "simulate_precipitation_null()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eca4bdc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25dd638",
   "metadata": {},
   "source": [
    "**Question 2.8.** Complete the simulation for the hypothesis test below. Your simulation should compute 5,000 values of the test statistic under the null hypothesis and store the result in the array `sampled_stats`.\n",
    "\n",
    "*Note:* Running this cell may take a few seconds. If it takes more than a minute, try to find a faster way to implement your `simulate_precipitation_null` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6a05df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:45.372177Z",
     "iopub.status.busy": "2022-04-01T19:48:45.371948Z",
     "iopub.status.idle": "2022-04-01T19:48:55.231743Z",
     "shell.execute_reply": "2022-04-01T19:48:55.231132Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampled_stats = ...\n",
    "\n",
    "...\n",
    "\n",
    "# Do not change these lines\n",
    "Table().with_column('Difference Between Means', sampled_stats).hist()\n",
    "plt.scatter(observed_statistic, 0, c=\"r\", s=50);\n",
    "plt.ylim(-0.01);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f478e3f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efbb752",
   "metadata": {},
   "source": [
    "**Question 2.9.** Compute the p-value for this hypothesis test, and assign it to the variable `precipitation_p_val`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a540061a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:48:55.268763Z",
     "iopub.status.busy": "2022-04-01T19:48:55.268215Z",
     "iopub.status.idle": "2022-04-01T19:48:55.272869Z",
     "shell.execute_reply": "2022-04-01T19:48:55.272318Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "precipitation_p_val = ...\n",
    "precipitation_p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8bbb65",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e16bcf8",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 2.10.** State a conclusion from this test using a p-value cutoff of 5%. What have you learned about the EPA's statement on drought?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17c7219",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c409d0",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 2.11.** Does your conclusion from Question 2.10 apply to the entire Southwest region of the U.S.? Why or why not?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4926a91a",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe9eb2a",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4e8526",
   "metadata": {},
   "source": [
    "Data science plays a central role in climate change research because massive simulations of the Earth's climate are necessary to assess the implications of climate data recorded from weather stations, satellites, and other sensors. [Berkeley Earth](http://berkeleyearth.org/data/) is a common source of data for these kinds of projects.\n",
    "\n",
    "In this part of the project, we found ways to apply our statistical inference technqiues that rely on random sampling even in situations where the data were not generated randomly, but instead by some complicated natural process that appeared random. We made assumptions about randomness and then came to conclusions based on those assumptions. Great care must be taken to choose assumptions that are realistic, so that the resulting conclusions are not misleading. However, making assumptions about data can be productive when doing so allows inference techniques to apply to novel situations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4973dbef",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49f1c1d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Congratulations on finishing the Project! Time to submit.**\n",
    "\n",
    "**Important submission steps:** \n",
    "1. Run the tests and verify that they all pass.\n",
    "2. Choose **Save Notebook** from the **File** menu. \n",
    "3. Submit **only** this notebook file to **Blackboard**. \n",
    "\n",
    "**It is your responsibility to make sure your work is saved before submission.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1_1_3": {
     "name": "q1_1_3",
     "points": [
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(num_unique_cites) in set([int, np.int32, np.int64])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # Make sure that num_unique_cities is greater than zero!\n>>> num_unique_cites > 0\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_1_4": {
     "name": "q1_1_4",
     "points": [
      0.5
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # Make sure the function outputs a string!\n>>> type(coordinates_to_region(50, 100)) == str\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_1_5": {
     "name": "q1_1_5",
     "points": [
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(cities.labels) == 8\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> cities.labels[-1] == \"Region\"\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_1_7": {
     "name": "q1_1_7",
     "points": [
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(regions_focus.labels) == 2\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> regions_focus.num_rows == 4\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_2_1": {
     "name": "q1_2_1",
     "points": [
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(largest_2010_range_date) == str or type(largest_2010_range_date) == numpy.str_\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_2_2": {
     "name": "q1_2_2",
     "points": [
      0,
      0,
      0.5
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> phoenix.num_rows == 46021\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> len(phoenix.labels) == 6\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> phoenix.labels == ('Date', 'tmax', 'tmin', 'prcp', 'Year', 'Month')\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_2_5": {
     "name": "q1_2_5",
     "points": [
      0,
      0,
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(period(2020)) == str\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> monthly_increases.num_rows == 12\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> monthly_increases.labels == ('Month', 'Past', 'Present', 'Increase')\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # Make sure your table is sorted from January to December.\n>>> monthly_increases.row(2).item('Month') == '03 (Mar)'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_2_6": {
     "name": "q1_2_6",
     "points": [
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(feb_present_ci) == np.float64\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_2_8": {
     "name": "q1_2_8",
     "points": [
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(months) == np.ndarray\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_1": {
     "name": "q2_1",
     "points": [
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> totals.num_rows == 61\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> totals.labels == ('Year', 'Precipitation')\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_4": {
     "name": "q2_4",
     "points": [
      0,
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(ab_test_stat) == np.ndarray\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all([1 <= option <= 6 for option in ab_test_stat])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all([type(option) in set([np.int64, np.int32, int]) for option in list(ab_test_stat)])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_6": {
     "name": "q2_6",
     "points": [
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> observed_statistic < 0\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_7": {
     "name": "q2_7",
     "points": [
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> -50 < simulate_precipitation_null() < 50\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_8": {
     "name": "q2_8",
     "points": [
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(sampled_stats) == 5000\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.std(sampled_stats) > 0\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_9": {
     "name": "q2_9",
     "points": [
      0,
      0.5
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(precipitation_p_val) in set([float, np.float32, np.float64])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> 0 <= precipitation_p_val <= 1\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
