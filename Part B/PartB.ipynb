{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cabdbd36-1375-459a-a864-b22762e93fcc",
   "metadata": {},
   "source": [
    "## 1. Preprocressing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43530994-53d2-4d35-9cbf-afbbb0bed939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datascience import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c0fa826-6ce1-4aac-9435-4d8e1946b79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>report_date</th> <th>report_source</th> <th>report_period</th> <th>ext_massacres_cum</th> <th>killed</th> <th>killed_cum</th> <th>ext_killed</th> <th>ext_killed_cum</th> <th>ext_killed_children_cum</th> <th>ext_killed_women_cum</th> <th>injured_cum</th> <th>ext_injured</th> <th>ext_injured_cum</th> <th>ext_civdef_killed_cum</th> <th>med_killed_cum</th> <th>ext_med_killed_cum</th> <th>press_killed_cum</th> <th>ext_press_killed_cum</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>2023-10-07 </td> <td>mohtel       </td> <td>24           </td> <td>0                </td> <td>232   </td> <td>232       </td> <td>232       </td> <td>232           </td> <td>0                      </td> <td>0                   </td> <td>1610       </td> <td>1610       </td> <td>1610           </td> <td>0                    </td> <td>6             </td> <td>6                 </td> <td>1               </td> <td>1                   </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-10-08 </td> <td>mohtel       </td> <td>24           </td> <td>0                </td> <td>138   </td> <td>370       </td> <td>138       </td> <td>370           </td> <td>78                     </td> <td>41                  </td> <td>1788       </td> <td>178        </td> <td>1788           </td> <td>0                    </td> <td>nan           </td> <td>6                 </td> <td>1               </td> <td>1                   </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-10-09 </td> <td>mohtel       </td> <td>24           </td> <td>8                </td> <td>190   </td> <td>560       </td> <td>190       </td> <td>560           </td> <td>91                     </td> <td>61                  </td> <td>2271       </td> <td>483        </td> <td>2271           </td> <td>0                    </td> <td>6             </td> <td>6                 </td> <td>3               </td> <td>3                   </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-10-10 </td> <td>mohtel       </td> <td>24           </td> <td>8                </td> <td>340   </td> <td>900       </td> <td>340       </td> <td>900           </td> <td>260                    </td> <td>230                 </td> <td>4000       </td> <td>1729       </td> <td>4000           </td> <td>0                    </td> <td>nan           </td> <td>6                 </td> <td>7               </td> <td>7                   </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-10-11 </td> <td>gmotel       </td> <td>24           </td> <td>23               </td> <td>200   </td> <td>1100      </td> <td>200       </td> <td>1100          </td> <td>398                    </td> <td>230                 </td> <td>5184       </td> <td>1184       </td> <td>5184           </td> <td>0                    </td> <td>10            </td> <td>10                </td> <td>nan             </td> <td>7                   </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-10-12 </td> <td>mohtel       </td> <td>24           </td> <td>23               </td> <td>317   </td> <td>1417      </td> <td>317       </td> <td>1417          </td> <td>500                    </td> <td>276                 </td> <td>5763       </td> <td>579        </td> <td>5763           </td> <td>0                    </td> <td>11            </td> <td>11                </td> <td>nan             </td> <td>7                   </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-10-13 </td> <td>missing      </td> <td>24           </td> <td>23               </td> <td>483   </td> <td>1900      </td> <td>483       </td> <td>1900          </td> <td>500                    </td> <td>392                 </td> <td>nan        </td> <td>1475       </td> <td>7238           </td> <td>0                    </td> <td>11            </td> <td>11                </td> <td>nan             </td> <td>7                   </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-10-14 </td> <td>gmotel       </td> <td>24           </td> <td>23               </td> <td>328   </td> <td>2228      </td> <td>328       </td> <td>2228          </td> <td>600                    </td> <td>600                 </td> <td>8714       </td> <td>1476       </td> <td>8714           </td> <td>0                    </td> <td>11            </td> <td>11                </td> <td>nan             </td> <td>7                   </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-10-15 </td> <td>gmotel       </td> <td>24           </td> <td>23               </td> <td>442   </td> <td>2670      </td> <td>442       </td> <td>2670          </td> <td>700                    </td> <td>735                 </td> <td>9200       </td> <td>486        </td> <td>9200           </td> <td>0                    </td> <td>nan           </td> <td>11                </td> <td>nan             </td> <td>7                   </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-10-16 </td> <td>gmotel       </td> <td>24           </td> <td>371              </td> <td>138   </td> <td>2808      </td> <td>138       </td> <td>2808          </td> <td>853                    </td> <td>936                 </td> <td>10850      </td> <td>1650       </td> <td>10850          </td> <td>7                    </td> <td>37            </td> <td>37                </td> <td>nan             </td> <td>7                   </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (541 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "daily_casualties_gaza = Table.read_table('casualties_daily_gaza_2025-04-12.csv')\n",
    "daily_casualties_gaza.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d3c0511-3c3d-4de5-bd15-4dacb1be7344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>report_date</th> <th>verified.killed</th> <th>verified.killed_cum</th> <th>verified.injured</th> <th>verified.injured_cum</th> <th>verified.killed_children</th> <th>verified.killed_children_cum</th> <th>verified.injured_children</th> <th>verified.injured_children_cum</th> <th>killed_cum</th> <th>killed_children_cum</th> <th>injured_cum</th> <th>injured_children_cum</th> <th>settler_attacks_cum</th> <th>flash_source</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>2023-10-07 </td> <td>6              </td> <td>6                  </td> <td>197             </td> <td>197                 </td> <td>2                       </td> <td>2                           </td> <td>31                       </td> <td>31                           </td> <td>3         </td> <td>0                  </td> <td>23         </td> <td>1                   </td> <td>3                  </td> <td>un          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-10-08 </td> <td>8              </td> <td>14                 </td> <td>127             </td> <td>324                 </td> <td>3                       </td> <td>5                           </td> <td>7                        </td> <td>38                           </td> <td>13        </td> <td>1                  </td> <td>194        </td> <td>1                   </td> <td>9                  </td> <td>un          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-10-09 </td> <td>4              </td> <td>18                 </td> <td>88              </td> <td>412                 </td> <td>0                       </td> <td>5                           </td> <td>19                       </td> <td>57                           </td> <td>15        </td> <td>3                  </td> <td>295        </td> <td>34                  </td> <td>19                 </td> <td>un          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-10-10 </td> <td>5              </td> <td>23                 </td> <td>72              </td> <td>484                 </td> <td>0                       </td> <td>5                           </td> <td>7                        </td> <td>64                           </td> <td>19        </td> <td>3                  </td> <td>332        </td> <td>39                  </td> <td>29                 </td> <td>un          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-10-11 </td> <td>6              </td> <td>29                 </td> <td>85              </td> <td>569                 </td> <td>2                       </td> <td>7                           </td> <td>17                       </td> <td>81                           </td> <td>26        </td> <td>3                  </td> <td>427        </td> <td>62                  </td> <td>39                 </td> <td>un          </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (546 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "daily_casualties_westbank = Table.read_table('casualties_daily_west_bank_2025-04-12.csv')\n",
    "daily_casualties_westbank.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c2b46332-65b5-4fda-a462-ddffc646fb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.6-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting pdfminer.six==20250327 (from pdfplumber)\n",
      "  Downloading pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: Pillow>=9.1 in /opt/anaconda3/lib/python3.12/site-packages (from pdfplumber) (10.4.0)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Downloading pypdfium2-4.30.1-py3-none-macosx_11_0_arm64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pdfminer.six==20250327->pdfplumber) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pdfminer.six==20250327->pdfplumber) (43.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/anaconda3/lib/python3.12/site-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.21)\n",
      "Downloading pdfplumber-0.11.6-py3-none-any.whl (60 kB)\n",
      "Downloading pdfminer_six-20250327-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-macosx_11_0_arm64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
      "Successfully installed pdfminer.six-20250327 pdfplumber-0.11.6 pypdfium2-4.30.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbbbae08-b67a-4bb0-9ef0-475a9c7cbad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pages 1 to 50...\n",
      "Processing pages 51 to 100...\n",
      "Processing pages 101 to 150...\n",
      "Processing pages 151 to 200...\n",
      "Processing pages 201 to 250...\n",
      "Processing pages 251 to 300...\n",
      "Processing pages 301 to 350...\n",
      "Processing pages 351 to 400...\n",
      "Processing pages 401 to 450...\n",
      "Processing pages 451 to 500...\n",
      "Processing pages 501 to 550...\n",
      "Processing pages 551 to 600...\n",
      "Processing pages 601 to 650...\n",
      "Processing pages 651 to 700...\n",
      "Processing pages 701 to 750...\n",
      "Processing pages 751 to 800...\n",
      "Processing pages 801 to 850...\n",
      "Processing pages 851 to 900...\n",
      "Processing pages 901 to 950...\n",
      "Processing pages 951 to 981...\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "# To ignore the warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger(\"pdfminer\").setLevel(logging.ERROR)\n",
    "\n",
    "with pdfplumber.open('killed-in-gaza_moh_2025-03-23.pdf') as pdf:\n",
    "    total_pages = len(pdf.pages)\n",
    "    batch_size = 50  # process 50 pages at a time\n",
    "    batch_number = 1\n",
    "    \n",
    "    for start_page in range(0, total_pages, batch_size):\n",
    "        end_page = min(start_page + batch_size, total_pages)\n",
    "        print(f\"Processing pages {start_page+1} to {end_page}...\")\n",
    "\n",
    "        batch_rows = []\n",
    "        columns = None\n",
    "\n",
    "        for page_num in range(start_page, end_page):\n",
    "            page = pdf.pages[page_num]\n",
    "            table = page.extract_table()\n",
    "            if table:\n",
    "                if columns is None:\n",
    "                    columns = table[0]  # first page -> header\n",
    "                    batch_rows.extend(table[1:])  # first page -> skip header\n",
    "                else:\n",
    "                    batch_rows.extend(table)  # other pages -> take all rows\n",
    "\n",
    "        if batch_rows:\n",
    "            # Building a small Table for this batch\n",
    "            batch_table = Table().with_columns(*[(col, []) for col in columns])\n",
    "\n",
    "            for row in batch_rows:\n",
    "                batch_table = batch_table.with_row(row)\n",
    "\n",
    "            # Saving this batch separately\n",
    "            filename = f'killed_in_gaza_batch_{batch_number}.csv'\n",
    "            batch_table.to_csv(filename)\n",
    "\n",
    "        batch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9ae262c-c7ca-4c97-b137-8aaf952e1932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Finding all CSV files\n",
    "csv_files = sorted(glob.glob('killed_in_gaza_batch_*.csv'))\n",
    "\n",
    "# Creating a file to store the combined output\n",
    "with open('killed_in_gaza.csv', 'w', encoding='utf-8-sig', newline='') as output_file:\n",
    "    writer = None\n",
    "\n",
    "    for filename in csv_files:\n",
    "        with open(filename, 'r', encoding='utf-8-sig') as f:\n",
    "            reader = csv.reader(f)\n",
    "            \n",
    "            if writer is None:\n",
    "                headers = next(reader)  # read header\n",
    "                writer = csv.writer(output_file)\n",
    "                writer.writerow(headers)\n",
    "\n",
    "            for row in reader:\n",
    "                writer.writerow(row)\n",
    "        os.remove(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a1ae3cb-53e7-4ea5-a767-1fe3d3cb61a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Index</th> <th>Name</th> <th>مس#ا</th> <th>Born</th> <th>Age</th> <th>Sex</th> <th>ID number</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>1    </td> <td>Mohammed Hani Mohammed Al-Zahhar</td> <td>راهزلا دمحم يناه دمحم    </td> <td>2023-08-09</td> <td>0   </td> <td>m   </td> <td>444196471</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2    </td> <td>Nour Mohammed Aed Udwan         </td> <td>ناودع دئاع دمحم رون      </td> <td>2023-02-27</td> <td>0   </td> <td>f   </td> <td>444484729</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3    </td> <td>Khaled Mumin Amin Shabir        </td> <td>ريبش 6ما نمؤم دلاخ       </td> <td>2023-04-16</td> <td>0   </td> <td>m   </td> <td>444799647</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>4    </td> <td>Yamen Ibrahim Farid Qaddoura    </td> <td>هرودق ديرف ميهاربا نماي  </td> <td>2023-06-10</td> <td>0   </td> <td>m   </td> <td>445958408</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>5    </td> <td>Ahmed Rami Ahmed Abdel Qadir    </td> <td>رداقلا دبع دمحأ يمار دمحأ</td> <td>2022-12-22</td> <td>0   </td> <td>m   </td> <td>445808546</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (50015 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "killed_in_gaza = Table.read_table('killed_in_gaza.csv')\n",
    "# killed_in_gaza.sort(\"Index\", descending=True).show(5)\n",
    "killed_in_gaza.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7320923-afeb-47a0-b074-0a93330d93e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50020"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "killed_in_gaza.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "17f83a9d-df79-4051-ba97-0ba4050ce4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Loading JSON\n",
    "with open('infrastructure-damaged_2025-04-12.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Flattening records\n",
    "flattened_data = []\n",
    "\n",
    "for record in data:\n",
    "    flat_record = {}\n",
    "    for key, value in record.items():\n",
    "        if isinstance(value, dict):\n",
    "            for sub_key, sub_value in value.items():\n",
    "                flat_record[f\"{key}_{sub_key}\"] = sub_value\n",
    "        else:\n",
    "            flat_record[key] = value\n",
    "    flattened_data.append(flat_record)\n",
    "\n",
    "# Finding all possible headers from all records\n",
    "all_keys = set()\n",
    "for row in flattened_data:\n",
    "    all_keys.update(row.keys())\n",
    "\n",
    "# headers = sorted(all_keys)\n",
    "\n",
    "# Saving to CSV\n",
    "with open('infrastructure_damaged.csv', 'w', newline='', encoding='utf-8-sig') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for row in flattened_data:\n",
    "        # filling missing keys with 0\n",
    "        complete_row = {key: row.get(key, 0) for key in headers}\n",
    "        writer.writerow(complete_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ef2edaa-adfe-4753-bb32-b5f597bd31f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>report_date</th> <th>civic_buildings_destroyed</th> <th>civic_buildings_ext_destroyed</th> <th>educational_buildings_damaged</th> <th>educational_buildings_destroyed</th> <th>educational_buildings_ext_damaged</th> <th>educational_buildings_ext_destroyed</th> <th>places_of_worship_churches_destroyed</th> <th>places_of_worship_ext_churches_destroyed</th> <th>places_of_worship_ext_mosques_damaged</th> <th>places_of_worship_ext_mosques_destroyed</th> <th>places_of_worship_mosques_damaged</th> <th>places_of_worship_mosques_destroyed</th> <th>residential_destroyed</th> <th>residential_ext_destroyed</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>2023-10-07 </td> <td>0                        </td> <td>5                            </td> <td>0                            </td> <td>0                              </td> <td>15                               </td> <td>1                                  </td> <td>0                                   </td> <td>0                                       </td> <td>4                                    </td> <td>2                                      </td> <td>0                                </td> <td>0                                  </td> <td>0                    </td> <td>80                       </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-10-08 </td> <td>0                        </td> <td>11                           </td> <td>0                            </td> <td>0                              </td> <td>30                               </td> <td>1                                  </td> <td>0                                   </td> <td>0                                       </td> <td>8                                    </td> <td>4                                      </td> <td>0                                </td> <td>0                                  </td> <td>159                  </td> <td>159                      </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-10-09 </td> <td>0                        </td> <td>16                           </td> <td>0                            </td> <td>0                              </td> <td>45                               </td> <td>2                                  </td> <td>0                                   </td> <td>0                                       </td> <td>12                                   </td> <td>6                                      </td> <td>0                                </td> <td>0                                  </td> <td>790                  </td> <td>790                      </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-10-10 </td> <td>0                        </td> <td>22                           </td> <td>0                            </td> <td>0                              </td> <td>60                               </td> <td>2                                  </td> <td>0                                   </td> <td>0                                       </td> <td>17                                   </td> <td>8                                      </td> <td>0                                </td> <td>0                                  </td> <td>1009                 </td> <td>1009                     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2023-10-11 </td> <td>27                       </td> <td>27                           </td> <td>75                           </td> <td>3                              </td> <td>75                               </td> <td>3                                  </td> <td>0                                   </td> <td>0                                       </td> <td>21                                   </td> <td>10                                     </td> <td>0                                </td> <td>10                                 </td> <td>2835                 </td> <td>2835                     </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (529 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "infrastructure_damaged = Table.read_table('infrastructure_damaged.csv')\n",
    "\n",
    "# Making report_date the first column\n",
    "labels = list(infrastructure_damaged.labels)\n",
    "labels.remove('report_date')\n",
    "new_order = ['report_date'] + labels  # Put it first\n",
    "\n",
    "# Rearrange the Table\n",
    "infrastructure_damaged = infrastructure_damaged.select(new_order)\n",
    "\n",
    "infrastructure_damaged.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1c61da0-58ce-40a6-98e3-1f68de7c7aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dataset_quality(table, dataset_name):\n",
    "    \"\"\"\n",
    "    Checks the quality of an entire datascience.Table dataset.\n",
    "    \n",
    "    Args:\n",
    "        table: A datascience.Table object\n",
    "        dataset_name: String with the name of the dataset for reporting\n",
    "    \n",
    "    Returns:\n",
    "        A datascience.Table with column quality metrics\n",
    "    \"\"\"\n",
    "    print(f\"\\n---------- CHECKING QUALITY OF {dataset_name} ----------\")\n",
    "    \n",
    "    # Initialize a results table\n",
    "    results = Table().with_columns(\n",
    "        'Column Name', [],\n",
    "        'Data Type', [],\n",
    "        'Count', [],\n",
    "        'Num Missing', [],\n",
    "        'Percent Missing', [],\n",
    "        'Num Unique Values', [],\n",
    "        'Min Value', [],\n",
    "        'Max Value', []\n",
    "    )\n",
    "    \n",
    "    # Get number of rows in the dataset\n",
    "    num_rows = table.num_rows\n",
    "    print(f\"Total rows: {num_rows}\")\n",
    "    \n",
    "    # Examine each column\n",
    "    for col_name in table.labels:\n",
    "        print(f\"\\nChecking column: {col_name}\")\n",
    "        \n",
    "        # Extract column as an array\n",
    "        col_values = table.column(col_name)\n",
    "        \n",
    "        # Get data type information\n",
    "        try:\n",
    "            example_value = col_values.item(0) if num_rows > 0 else None\n",
    "            data_type = type(example_value).__name__\n",
    "        except:\n",
    "            data_type = \"unknown\"\n",
    "        \n",
    "        # Count missing values (None values)\n",
    "        none_count = 0\n",
    "        try:\n",
    "            none_count = table.where(col_name, are.equal_to(None)).num_rows\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        # Try to calculate missing numeric values (np.nan)\n",
    "        nan_count = 0\n",
    "        try:\n",
    "            # For numeric columns, check if values are NaN\n",
    "            if data_type in ('int', 'float'):\n",
    "                # Count NaN values using the datascience apply method\n",
    "                # We define a simple function that checks if a value is a NaN\n",
    "                def is_nan(x):\n",
    "                    try:\n",
    "                        return np.isnan(x)\n",
    "                    except:\n",
    "                        return False\n",
    "                \n",
    "                # Apply the function to count NaNs\n",
    "                nan_array = table.apply(is_nan, col_name)\n",
    "                nan_count = sum(nan_array)\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        # Count empty strings for text columns\n",
    "        empty_count = 0\n",
    "        try:\n",
    "            if data_type == 'str':\n",
    "                empty_count = table.where(col_name, are.equal_to('')).num_rows\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        # Total missing\n",
    "        total_missing = none_count + nan_count + empty_count\n",
    "        percent_missing = (total_missing / num_rows * 100) if num_rows > 0 else 0\n",
    "        \n",
    "        # Count unique values\n",
    "        unique_count = 0\n",
    "        try:\n",
    "            # Group by the column and count unique values\n",
    "            unique_count = table.group(col_name).num_rows\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        # Try to get min and max for numeric columns\n",
    "        min_value = \"N/A\"\n",
    "        max_value = \"N/A\"\n",
    "        try:\n",
    "            if data_type in ('int', 'float'):\n",
    "                # Filter out None values for min/max calculation\n",
    "                valid_values = table.where(col_name, are.not_equal_to(None)).column(col_name)\n",
    "                if len(valid_values) > 0:\n",
    "                    min_value = min(valid_values)\n",
    "                    max_value = max(valid_values)\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        # Add results to the table\n",
    "        results = results.with_row([\n",
    "            col_name,\n",
    "            data_type,\n",
    "            num_rows,\n",
    "            total_missing,\n",
    "            round(percent_missing, 2),\n",
    "            unique_count,\n",
    "            min_value,\n",
    "            max_value\n",
    "        ])\n",
    "            \n",
    "    # Print a summary of problems found\n",
    "    problem_cols = results.where('Percent Missing', are.above(0))\n",
    "    \n",
    "    if problem_cols.num_rows > 0:\n",
    "        print(\"\\n----- SUMMARY OF DATA QUALITY ISSUES -----\")\n",
    "        print(f\"Found {problem_cols.num_rows} columns with missing values:\")\n",
    "        problem_cols.select('Column Name', 'Percent Missing').show()\n",
    "    else:\n",
    "        print(\"\\nNo missing values found in any columns!\")\n",
    "        \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "095cbc35-e402-4e00-8a44-84266899a079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- CHECKING QUALITY OF GAZA CASUALTIES ----------\n",
      "Total rows: 551\n",
      "\n",
      "Checking column: report_date\n",
      "\n",
      "Checking column: report_source\n",
      "\n",
      "Checking column: report_period\n",
      "\n",
      "Checking column: ext_massacres_cum\n",
      "\n",
      "Checking column: killed\n",
      "\n",
      "Checking column: killed_cum\n",
      "\n",
      "Checking column: ext_killed\n",
      "\n",
      "Checking column: ext_killed_cum\n",
      "\n",
      "Checking column: ext_killed_children_cum\n",
      "\n",
      "Checking column: ext_killed_women_cum\n",
      "\n",
      "Checking column: injured_cum\n",
      "\n",
      "Checking column: ext_injured\n",
      "\n",
      "Checking column: ext_injured_cum\n",
      "\n",
      "Checking column: ext_civdef_killed_cum\n",
      "\n",
      "Checking column: med_killed_cum\n",
      "\n",
      "Checking column: ext_med_killed_cum\n",
      "\n",
      "Checking column: press_killed_cum\n",
      "\n",
      "Checking column: ext_press_killed_cum\n",
      "\n",
      "----- SUMMARY OF DATA QUALITY ISSUES -----\n",
      "Found 5 columns with missing values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Column Name</th> <th>Percent Missing</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>killed          </td> <td>4.9            </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>killed_cum      </td> <td>1.27           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>injured_cum     </td> <td>2.72           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>med_killed_cum  </td> <td>75.68          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>press_killed_cum</td> <td>74.23          </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- CHECKING QUALITY OF WEST BANK CASUALTIES ----------\n",
      "Total rows: 551\n",
      "\n",
      "Checking column: report_date\n",
      "\n",
      "Checking column: verified.killed\n",
      "\n",
      "Checking column: verified.killed_cum\n",
      "\n",
      "Checking column: verified.injured\n",
      "\n",
      "Checking column: verified.injured_cum\n",
      "\n",
      "Checking column: verified.killed_children\n",
      "\n",
      "Checking column: verified.killed_children_cum\n",
      "\n",
      "Checking column: verified.injured_children\n",
      "\n",
      "Checking column: verified.injured_children_cum\n",
      "\n",
      "Checking column: killed_cum\n",
      "\n",
      "Checking column: killed_children_cum\n",
      "\n",
      "Checking column: injured_cum\n",
      "\n",
      "Checking column: injured_children_cum\n",
      "\n",
      "Checking column: settler_attacks_cum\n",
      "\n",
      "Checking column: flash_source\n",
      "\n",
      "----- SUMMARY OF DATA QUALITY ISSUES -----\n",
      "Found 8 columns with missing values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Column Name</th> <th>Percent Missing</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>verified.killed              </td> <td>26.86          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>verified.killed_cum          </td> <td>26.68          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>verified.injured             </td> <td>29.4           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>verified.injured_cum         </td> <td>29.04          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>verified.killed_children     </td> <td>26.86          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>verified.killed_children_cum </td> <td>26.68          </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>verified.injured_children    </td> <td>29.4           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>verified.injured_children_cum</td> <td>29.04          </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- CHECKING QUALITY OF INFRASTRUCTURE DAMAGE ----------\n",
      "Total rows: 534\n",
      "\n",
      "Checking column: report_date\n",
      "\n",
      "Checking column: civic_buildings_destroyed\n",
      "\n",
      "Checking column: civic_buildings_ext_destroyed\n",
      "\n",
      "Checking column: educational_buildings_damaged\n",
      "\n",
      "Checking column: educational_buildings_destroyed\n",
      "\n",
      "Checking column: educational_buildings_ext_damaged\n",
      "\n",
      "Checking column: educational_buildings_ext_destroyed\n",
      "\n",
      "Checking column: places_of_worship_churches_destroyed\n",
      "\n",
      "Checking column: places_of_worship_ext_churches_destroyed\n",
      "\n",
      "Checking column: places_of_worship_ext_mosques_damaged\n",
      "\n",
      "Checking column: places_of_worship_ext_mosques_destroyed\n",
      "\n",
      "Checking column: places_of_worship_mosques_damaged\n",
      "\n",
      "Checking column: places_of_worship_mosques_destroyed\n",
      "\n",
      "Checking column: residential_destroyed\n",
      "\n",
      "Checking column: residential_ext_destroyed\n",
      "\n",
      "No missing values found in any columns!\n",
      "\n",
      "---------- CHECKING QUALITY OF KILLED IN GAZA ----------\n",
      "Total rows: 50020\n",
      "\n",
      "Checking column: Index\n",
      "\n",
      "Checking column: Name\n",
      "\n",
      "Checking column: مس#ا\n",
      "\n",
      "Checking column: Born\n",
      "\n",
      "Checking column: Age\n",
      "\n",
      "Checking column: Sex\n",
      "\n",
      "Checking column: ID number\n",
      "\n",
      "No missing values found in any columns!\n",
      "\n",
      "---------- OVERALL DATASET SUMMARY ----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Dataset</th> <th>Rows</th> <th>Columns</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Gaza Casualties      </td> <td>551  </td> <td>18     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>West Bank Casualties </td> <td>551  </td> <td>15     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Infrastructure Damage</td> <td>534  </td> <td>15     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Killed in Gaza       </td> <td>50020</td> <td>7      </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to check all datasets\n",
    "def check_all_datasets_quality():\n",
    "    \"\"\"Checks all datasets for quality issues using the datascience library\"\"\"\n",
    "    \n",
    "    # Check each dataset\n",
    "    gaza_results = check_dataset_quality(daily_casualties_gaza, \"GAZA CASUALTIES\")\n",
    "    westbank_results = check_dataset_quality(daily_casualties_westbank, \"WEST BANK CASUALTIES\")\n",
    "    infra_results = check_dataset_quality(infrastructure_damaged, \"INFRASTRUCTURE DAMAGE\")\n",
    "    killed_results = check_dataset_quality(killed_in_gaza, \"KILLED IN GAZA\")\n",
    "    \n",
    "    # Create a combined summary table\n",
    "    all_datasets = Table().with_columns(\n",
    "        'Dataset', ['Gaza Casualties', 'West Bank Casualties', 'Infrastructure Damage', 'Killed in Gaza'],\n",
    "        'Rows', [\n",
    "            daily_casualties_gaza.num_rows,\n",
    "            daily_casualties_westbank.num_rows,\n",
    "            infrastructure_damaged.num_rows,\n",
    "            killed_in_gaza.num_rows\n",
    "        ],\n",
    "        'Columns', [\n",
    "            len(daily_casualties_gaza.labels),\n",
    "            len(daily_casualties_westbank.labels),\n",
    "            len(infrastructure_damaged.labels),\n",
    "            len(killed_in_gaza.labels)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(\"\\n---------- OVERALL DATASET SUMMARY ----------\")\n",
    "    all_datasets.show()\n",
    "    \n",
    "    return gaza_results, westbank_results, infra_results, killed_results\n",
    "\n",
    "# Run the check for all datasets\n",
    "gaza_results, westbank_results, infra_results, killed_results = check_all_datasets_quality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3718248-d3b0-47dd-9b50-41975f92d1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fabfe247-e995-4d80-a5e1-8d290e0c6235",
   "metadata": {},
   "source": [
    "## 2. Exploratory Analysis & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01373f44-d1a2-4895-9b68-328681c1a98f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39212e78-214e-4ae0-89bc-7559ea9911d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3336077-0e3d-4690-9480-79098117fa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# casualities over time for gaza, westbank (overlaid line plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f328092-6813-488e-97e8-d6b19aa1decf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age groups (in ranges) histogram (killed in gaza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5f66e1-7f00-41ba-b76e-20a6bbb47e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join by report_date, number of building vs num killed in gaza (scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4270c896-7a12-40cd-ad70-cf85dd6e7c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by gender (killed in gaza) bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c5adde-549b-4115-88d7-af28e821cdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# something for period of ceasefire vs normal casualities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc0ddcb-a239-41dd-8688-cb869a1b3862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select just medical killed column vs time (and press)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd568a3-fc93-410e-8397-e50cba01cf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settler attacks vs casualities over time in westband"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaea4c4a-7eaf-4433-bc07-817397dc52b1",
   "metadata": {},
   "source": [
    "## 3. Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656ecd97-0c78-4b32-a606-ac7d72a525f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# null: woman and men are being targetted equally\n",
    "# alternative: woman are being targetted more/ children\n",
    "# statistic: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842199cc-bd3e-4f7a-aaaa-0a3cc73d2511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# null: all ages are being targetted equally\n",
    "# alternative: younger people (under a certain age)\n",
    "# use td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ea957d-032b-4c9c-8676-6ddd1c4c7c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# \n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
